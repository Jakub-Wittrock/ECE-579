{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a5d7ce",
   "metadata": {},
   "source": [
    "# MEL Spectrogram 3 Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48f311",
   "metadata": {},
   "source": [
    "We can extend our dataset by creating windows for each of the mel spectrograms. This will allow us to have more training data and improve the performance of our model. We will create windows of 3 seconds for each mel spectrogram, which will give us a total of 10 windows for each mel spectrogram. This will increase our dataset from 1000 samples to 10000 samples, which will help our model learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204627f3",
   "metadata": {},
   "source": [
    "This process is known as data augmentation, and it is a common technique used in machine learning to increase the size of the training dataset and improve the performance of the model. By creating windows for each mel spectrogram, we are effectively creating new samples that can be used for training, which can help our model learn better and generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f17751",
   "metadata": {},
   "source": [
    "## Slicing Mel Spectrograms into 3 Second Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada086ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e43d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\images_original\"\n",
    "SAVE_PATH = r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\images_3_sec_split\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d84bb0",
   "metadata": {},
   "source": [
    "We will have to get rid of the white space in our mel spectrograms, which will allow us to have a more compact representation of our data. This will help our model learn better and improve the performance of our model. We will use the `numpy` library to remove the white space from our mel spectrograms, which will give us a more compact representation of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e4c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_white_borders(img):\n",
    "    # Convert to grayscale to find the boundaries\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the image: anything not white becomes 0 (black)\n",
    "    # We use 254 to catch \"almost white\" pixels too\n",
    "    _, thresh = cv2.threshold(gray, 254, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find the coordinates of all non-zero pixels\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    \n",
    "    # Get the bounding box of those coordinates\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "\n",
    "    # Crop the original image to that bounding box\n",
    "    return img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f5412",
   "metadata": {},
   "source": [
    "We are now ready to slice the spectrogram into 3 second windows. This will allow us to have more training data and improve the performance of our model. We will use the `numpy` library to slice our spectrograms into 3 second windows, which will give us a total of 10 windows for each mel spectrogram. This will increase our dataset from 1000 samples to 10000 samples, which will help our model learn better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66490ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_spectrograms(source_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is None: continue\n",
    "        \n",
    "                #Crop Image To Remove Border\n",
    "                cropped_img = crop_white_borders(img)\n",
    "\n",
    "                # Get dimensions\n",
    "                h, w, _ = cropped_img.shape\n",
    "\n",
    "                # Calculate width of one 3-second slice\n",
    "                slice_width = w // 10 \n",
    "                \n",
    "                # Get genre name from the folder\n",
    "                genre = os.path.basename(root)\n",
    "                genre_out_path = os.path.join(output_dir, genre)\n",
    "                os.makedirs(genre_out_path, exist_ok=True)\n",
    "\n",
    "                for i in range(10):\n",
    "                    start_x = i * slice_width\n",
    "                    end_x = (i + 1) * slice_width\n",
    "                    \n",
    "                    # Slice the image [y_start:y_end, x_start:x_end]\n",
    "                    slice_img = cropped_img[:, start_x:end_x]\n",
    "                    \n",
    "                    # Resize to your model's target (e.g., 128x128)\n",
    "                    slice_img = cv2.resize(slice_img, (128, 128))\n",
    "                    \n",
    "                    # Construct name: blues.00000.0.png, blues.00000.1.png\n",
    "                    base_name = file.replace(\".png\", \"\")\n",
    "                    new_filename = f\"{base_name}.{i}.png\"\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(genre_out_path, new_filename), slice_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c4fde8",
   "metadata": {},
   "source": [
    "Let's call the method so we can create the splits and create a new folder for our augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc084219",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_spectrograms(BASE_PATH,SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6d12b",
   "metadata": {},
   "source": [
    "We will now make a slice folder that will have test and train split data that we will use in other notebooks in our project. This workflow will allow us to have a more organized structure for our data and make it easier to use in our model training and evaluation. We will use the `os` library to create the necessary folders and move the sliced spectrograms into the appropriate folders for training and testing. This will help us keep our data organized and make it easier to access when we need it for our model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d9626d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to the raw dataset\n",
    "BASE_PATH = r'C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset'\n",
    "IMAGES_PATH = os.path.join(BASE_PATH,\"images_3_sec_split\")\n",
    "\n",
    "#Path to where we will move the split data\n",
    "SPLIT_BASE_PATH = r'C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\Split GTZAN Dataset3 Sec'\n",
    "SPLIT_TRAIN_PATH = os.path.join(SPLIT_BASE_PATH, 'train')\n",
    "SPLIT_TEST_PATH = os.path.join(SPLIT_BASE_PATH, 'test')\n",
    "\n",
    "\n",
    "#Make the target base path and the train and text split directories\n",
    "os.makedirs(SPLIT_BASE_PATH,exist_ok = True)\n",
    "os.makedirs(SPLIT_TRAIN_PATH,exist_ok = True)\n",
    "os.makedirs(SPLIT_TEST_PATH,exist_ok = True)\n",
    "\n",
    "#Let's also include all the subfolders for train and test\n",
    "for label in os.listdir(IMAGES_PATH):\n",
    "\n",
    "    train_path = os.path.join(SPLIT_TRAIN_PATH,label)\n",
    "    test_path = os.path.join(SPLIT_TEST_PATH,label)\n",
    "\n",
    "    os.makedirs(train_path,exist_ok = True)\n",
    "    os.makedirs(test_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2171539",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for root, dirs, files in os.walk(IMAGES_PATH):\n",
    "    \n",
    "    image_paths = []    \n",
    "    try:\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root,file)\n",
    "            image_paths.append(file_path)\n",
    "\n",
    "        key = file.split('0')[0]\n",
    "        images[key] = image_paths\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b78c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in images.keys():\n",
    "    np.random.shuffle(images[key]) \n",
    "\n",
    "    for i,image in enumerate(images[key]):\n",
    "\n",
    "        if i < int(0.8*len(images[key])):\n",
    "            genre = key\n",
    "            image_name = os.path.basename(image)\n",
    "            destination_path = os.path.join(SPLIT_TRAIN_PATH,genre,image_name)\n",
    "            shutil.copyfile(image,destination_path)\n",
    "\n",
    "        else:\n",
    "            image_name = os.path.basename(image)\n",
    "            genre = key\n",
    "            destination_path = os.path.join(SPLIT_TEST_PATH,genre,image_name)\n",
    "            shutil.copyfile(image,destination_path)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33c1f3",
   "metadata": {},
   "source": [
    "## Connecting 3 Second Windows to Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23614c1e",
   "metadata": {},
   "source": [
    "The dataset also includes a CSV file that contains the labels for each of the mel spectrograms. We will need to connect the 3 second windows to their corresponding labels in order to use them for training our model. We will use the `pandas` library to read the CSV file and create a mapping between the 3 second windows and their corresponding labels. This will allow us to use the augmented data for training our model and improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9afbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88bb5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBROSA_PATH = r'C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\features_3_sec.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd2c43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LIBROSA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03006046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
      "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
      "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
      "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
      "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.003521             1773.065032          167541.630869   \n",
      "1  0.001450             1816.693777           90525.690866   \n",
      "2  0.004620             1788.539719          111407.437613   \n",
      "3  0.002448             1655.289045          111952.284517   \n",
      "4  0.001701             1630.656199           79667.267654   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0              1972.744388           117335.771563  ...   39.687145   \n",
      "1              2010.051501            65671.875673  ...   64.748276   \n",
      "2              2084.565132            75124.921716  ...   67.336563   \n",
      "3              1960.039988            82913.639269  ...   47.739452   \n",
      "4              1948.503884            60204.020268  ...   30.336359   \n",
      "\n",
      "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
      "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
      "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
      "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
      "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
      "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
      "\n",
      "   mfcc20_mean  mfcc20_var  label  \n",
      "0    -0.243027   43.771767  blues  \n",
      "1     5.784063   59.943081  blues  \n",
      "2     2.517375   33.105122  blues  \n",
      "3     3.630866   32.023678  blues  \n",
      "4     0.536961   29.146694  blues  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf28a8c",
   "metadata": {},
   "source": [
    "We can create a mapping between the 3 second windows and their corresponding labels by using the `pandas` library to read the CSV file and create a dictionary that maps each 3 second window to its corresponding label. This will allow us to easily access the labels for each of the 3 second windows when we are training our model. We can then use this mapping to create our training and testing datasets, which will include both the 3 second windows and their corresponding labels. This will help us train our model more effectively and improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a682a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
      "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
      "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
      "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
      "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.003521             1773.065032          167541.630869   \n",
      "1  0.001450             1816.693777           90525.690866   \n",
      "2  0.004620             1788.539719          111407.437613   \n",
      "3  0.002448             1655.289045          111952.284517   \n",
      "4  0.001701             1630.656199           79667.267654   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc17_mean  \\\n",
      "0              1972.744388           117335.771563  ...    -3.241280   \n",
      "1              2010.051501            65671.875673  ...    -6.055294   \n",
      "2              2084.565132            75124.921716  ...    -1.768610   \n",
      "3              1960.039988            82913.639269  ...    -3.841155   \n",
      "4              1948.503884            60204.020268  ...     0.664582   \n",
      "\n",
      "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
      "0   36.488243     0.722209   38.099152    -5.050335   33.618073    -0.243027   \n",
      "1   40.677654     0.159015   51.264091    -2.837699   97.030830     5.784063   \n",
      "2   28.348579     2.378768   45.717648    -1.938424   53.050835     2.517375   \n",
      "3   28.337118     1.218588   34.770935    -3.580352   50.836224     3.630866   \n",
      "4   45.880913     1.689446   51.363583    -3.392489   26.738789     0.536961   \n",
      "\n",
      "   mfcc20_var  label         image_name  \n",
      "0   43.771767  blues  blues.00000.0.png  \n",
      "1   59.943081  blues  blues.00000.1.png  \n",
      "2   33.105122  blues  blues.00000.2.png  \n",
      "3   32.023678  blues  blues.00000.3.png  \n",
      "4   29.146694  blues  blues.00000.4.png  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "df['image_name'] = df['filename'].str.replace('.wav','.png')\n",
    "\n",
    "#Print the head of the dataframe to make sure the replacement was successful\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3b005",
   "metadata": {},
   "source": [
    "We will make a simple loop that will demonnstrate how to match a file to it's corresponding label in the CSV file. This will allow us to create our training and testing datasets with the correct labels for each of the 3 second windows. By doing this, we can ensure that our model is trained on the correct data and can learn to make accurate predictions based on the labels provided in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(SPLIT_BASE_PATH):\n",
    "    for file in files:\n",
    "        print(df.loc[df['image_name'] == file].values.reshape(-1)[2:59])\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE579",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
