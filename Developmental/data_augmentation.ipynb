{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a5d7ce",
   "metadata": {},
   "source": [
    "# MEL Spectrogram 3 Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48f311",
   "metadata": {},
   "source": [
    "We can extend our dataset by creating windows for each of the mel spectrograms. This will allow us to have more training data and improve the performance of our model. We will create windows of 3 seconds for each mel spectrogram, which will give us a total of 10 windows for each mel spectrogram. This will increase our dataset from 1000 samples to 10000 samples, which will help our model learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204627f3",
   "metadata": {},
   "source": [
    "This process is known as data augmentation, and it is a common technique used in machine learning to increase the size of the training dataset and improve the performance of the model. By creating windows for each mel spectrogram, we are effectively creating new samples that can be used for training, which can help our model learn better and generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75b238",
   "metadata": {},
   "source": [
    "## Generating MEL Spectrogram Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f2af0",
   "metadata": {},
   "source": [
    "Let's start by loading the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6b0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77350966",
   "metadata": {},
   "source": [
    "Next we will define a funcition that will process the dataset we provide it and generate the mel spectrogram windows for each sample in the dataset. This function will take in the dataset and the window size as input and will return a new dataset with the generated windows.\n",
    "\n",
    "This function will iterate through each sample in the dataset, generate the mel spectrogram for the sample, and then create windows of the specified size from the mel spectrogram. The generated windows will be stored in a new dataset, which will be returned at the end of the function.\n",
    "\n",
    "Additionally, we will use librosa to extract features from the audio files and create the mel spectrograms. We will also use numpy to handle the data manipulation and storage of the generated windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70e8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_windowed(\n",
    "    dataset_dir: str,\n",
    "    output_img_dir: str,\n",
    "    output_csv: str,\n",
    "    window_sec: float = 3.0,\n",
    "    sr: int = 22050,\n",
    "    n_mels: int = 128,\n",
    "    n_fft: int = 2048,\n",
    "    hop_length: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a categorized audio dataset using fixed 3-second windows.\n",
    "    Generates mel spectrogram PNGs and extracts librosa features per window.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "    records = []\n",
    "\n",
    "    window_samples = int(window_sec * sr)\n",
    "\n",
    "    for label in sorted(os.listdir(dataset_dir)):\n",
    "        class_dir = os.path.join(dataset_dir, label)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        class_img_dir = os.path.join(output_img_dir, label)\n",
    "        os.makedirs(class_img_dir, exist_ok=True)\n",
    "\n",
    "        for file in os.listdir(class_dir):\n",
    "            if not file.lower().endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "\n",
    "            try:\n",
    "\n",
    "                wav_path = os.path.join(class_dir, file)\n",
    "                y, sr = librosa.load(wav_path, sr=sr, mono=True)\n",
    "\n",
    "                num_windows = len(y) // window_samples\n",
    "\n",
    "                for w in range(num_windows):\n",
    "                    start = w * window_samples\n",
    "                    end = start + window_samples\n",
    "                    y_win = y[start:end]\n",
    "\n",
    "                    win_id = f\"{file[:-4]}_w{w:03d}\"\n",
    "                    img_path = os.path.join(class_img_dir, f\"{win_id}.png\")\n",
    "\n",
    "                    # ------------------ Mel Spectrogram (RGB, 128x128) ------------------\n",
    "                    mel = librosa.feature.melspectrogram(\n",
    "                        y=y_win,\n",
    "                        sr=sr,\n",
    "                        n_fft=n_fft,\n",
    "                        hop_length=hop_length,\n",
    "                        n_mels=128\n",
    "                    )\n",
    "                    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "                    # Normalize to [0, 1]\n",
    "                    mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-6)\n",
    "\n",
    "                    # Apply colormap (returns RGBA)\n",
    "                    mel_rgb = cm.viridis(mel_norm)\n",
    "\n",
    "                    # Drop alpha channel, convert to uint8\n",
    "                    mel_rgb = (mel_rgb[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "                    # Resize to EXACT 128x128\n",
    "                    mel_rgb = cv2.resize(\n",
    "                        mel_rgb,\n",
    "                        (128, 128),\n",
    "                        interpolation=cv2.INTER_AREA\n",
    "                    )\n",
    "\n",
    "                    # Save PNG (RGB)\n",
    "                    cv2.imwrite(img_path, cv2.cvtColor(mel_rgb, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "                    # ------------------ Feature Extraction ------------------\n",
    "                    row = {\n",
    "                        \"label\": label,\n",
    "                        \"file\": file,\n",
    "                        \"window\": w\n",
    "                    }\n",
    "\n",
    "                    chroma = librosa.feature.chroma_stft(y=y_win, sr=sr)\n",
    "                    row[\"chroma_stft_mean\"] = chroma.mean()\n",
    "                    row[\"chroma_stft_var\"] = chroma.var()\n",
    "\n",
    "                    rms = librosa.feature.rms(y=y_win)\n",
    "                    row[\"rms_mean\"] = rms.mean()\n",
    "                    row[\"rms_var\"] = rms.var()\n",
    "\n",
    "                    centroid = librosa.feature.spectral_centroid(y=y_win, sr=sr)\n",
    "                    row[\"spectral_centroid_mean\"] = centroid.mean()\n",
    "                    row[\"spectral_centroid_var\"] = centroid.var()\n",
    "\n",
    "                    bandwidth = librosa.feature.spectral_bandwidth(y=y_win, sr=sr)\n",
    "                    row[\"spectral_bandwidth_mean\"] = bandwidth.mean()\n",
    "                    row[\"spectral_bandwidth_var\"] = bandwidth.var()\n",
    "\n",
    "                    rolloff = librosa.feature.spectral_rolloff(y=y_win, sr=sr)\n",
    "                    row[\"rolloff_mean\"] = rolloff.mean()\n",
    "                    row[\"rolloff_var\"] = rolloff.var()\n",
    "\n",
    "                    zcr = librosa.feature.zero_crossing_rate(y_win)\n",
    "                    row[\"zero_crossing_rate_mean\"] = zcr.mean()\n",
    "                    row[\"zero_crossing_rate_var\"] = zcr.var()\n",
    "\n",
    "                    y_harm = librosa.effects.harmonic(y_win)\n",
    "                    row[\"harmony_mean\"] = y_harm.mean()\n",
    "                    row[\"harmony_var\"] = y_harm.var()\n",
    "\n",
    "                    perceptr = librosa.feature.spectral_contrast(y=y_win, sr=sr)\n",
    "                    row[\"perceptr_mean\"] = perceptr.mean()\n",
    "                    row[\"perceptr_var\"] = perceptr.var()\n",
    "\n",
    "                    tempo, _ = librosa.beat.beat_track(y=y_win, sr=sr)\n",
    "                    row[\"tempo\"] = float(tempo)\n",
    "\n",
    "                    mfcc = librosa.feature.mfcc(y=y_win, sr=sr, n_mfcc=20)\n",
    "                    for i in range(20):\n",
    "                        row[f\"mfcc{i+1}_mean\"] = mfcc[i].mean()\n",
    "                        row[f\"mfcc{i+1}_var\"] = mfcc[i].var()\n",
    "\n",
    "                    records.append(row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}. Skipping.......\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved {len(df)} windowed samples → {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a2e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JTWit\\AppData\\Local\\Temp\\ipykernel_3944\\4270111457.py:119: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  row[\"tempo\"] = float(tempo)\n",
      "C:\\Users\\JTWit\\AppData\\Local\\Temp\\ipykernel_3944\\4270111457.py:37: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_path, sr=sr, mono=True)\n",
      "c:\\Users\\JTWit\\AppData\\Local\\spyder-6\\envs\\ECE579\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file jazz.00054.wav: . Skipping.......\n",
      "Saved 9981 windowed samples → audio_features.csv\n"
     ]
    }
   ],
   "source": [
    "audio_dir = r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\genres_original\"\n",
    "img_dir = r\"C:\\Users\\JTWit\\Desktop\\GTZAN 3 Seconds\"\n",
    "\n",
    "process_dataset_windowed(\n",
    "    dataset_dir=audio_dir,\n",
    "    output_img_dir=img_dir,\n",
    "    output_csv=\"audio_features.csv\",\n",
    "    window_sec=3.0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4b2ca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label             file  window  chroma_stft_mean  chroma_stft_var  \\\n",
      "0  blues  blues.00000.wav       0          0.335555         0.090997   \n",
      "1  blues  blues.00000.wav       1          0.343523         0.086782   \n",
      "2  blues  blues.00000.wav       2          0.347746         0.092495   \n",
      "3  blues  blues.00000.wav       3          0.363863         0.087207   \n",
      "4  blues  blues.00000.wav       4          0.335481         0.088482   \n",
      "\n",
      "   rms_mean   rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.130189  0.003559             1773.358004          169450.829707   \n",
      "1  0.112119  0.001491             1817.244034           90766.297514   \n",
      "2  0.130895  0.004552             1790.722358          110071.206762   \n",
      "3  0.131349  0.002338             1660.545231          109496.936309   \n",
      "4  0.142370  0.001734             1634.465076           77425.419156   \n",
      "\n",
      "   spectral_bandwidth_mean  ...  mfcc16_var  mfcc17_mean  mfcc17_var  \\\n",
      "0              1972.334258  ...   39.547077    -3.230046   36.606857   \n",
      "1              2010.751494  ...   64.819780    -6.025473   40.548813   \n",
      "2              2088.184750  ...   68.306790    -1.714475   28.136944   \n",
      "3              1967.920582  ...   48.543200    -3.786986   28.419546   \n",
      "4              1954.633566  ...   30.829542     0.635798   44.645554   \n",
      "\n",
      "   mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \\\n",
      "0     0.696385   37.766136    -5.035945   33.668550    -0.239585   43.818886   \n",
      "1     0.127131   51.048943    -2.808956   97.221504     5.771881   60.360348   \n",
      "2     2.329553   47.211426    -1.925621   52.922424     2.466996   33.163998   \n",
      "3     1.153315   35.682700    -3.501979   50.610344     3.580636   32.325880   \n",
      "4     1.591107   51.415867    -3.364908   26.421090     0.501504   29.109533   \n",
      "\n",
      "             image_file  \n",
      "0  blues.00000_w000.png  \n",
      "1  blues.00000_w001.png  \n",
      "2  blues.00000_w002.png  \n",
      "3  blues.00000_w003.png  \n",
      "4  blues.00000_w004.png  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\audio_features.csv\")\n",
    "\n",
    "\n",
    "# Function to create image filename\n",
    "def get_image_filename(row):\n",
    "    label = row['label']\n",
    "    number = row['file'].split('.')[1]\n",
    "    window_padded = f\"{row['window']:03d}\"  # Pad window with 3 digits\n",
    "    return f\"{label}.{number}_w{window_padded}.png\"\n",
    "\n",
    "# Add new column\n",
    "df['image_file'] = df.apply(get_image_filename, axis=1)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\GTZAN Dataset\\audio_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590173f3",
   "metadata": {},
   "source": [
    "Now that we have 3 second windows for each sample, we will split the dataset into training and testing sets. This will allow us to evaluate the performance of our model on unseen data and ensure that it is not overfitting to the training data.\n",
    "\n",
    "We will reuse some code from dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cfe2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = r\"C:\\Users\\JTWit\\Desktop\\GTZAN 3 Seconds\"\n",
    "\n",
    "SPLIT_BASE_PATH = r'C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\Split GTZAN Dataset 3s'\n",
    "SPLIT_TRAIN_PATH = os.path.join(SPLIT_BASE_PATH, 'train')\n",
    "SPLIT_TEST_PATH = os.path.join(SPLIT_BASE_PATH, 'test')\n",
    "\n",
    "#Make the target base path and the train and text split directories\n",
    "os.makedirs(SPLIT_BASE_PATH,exist_ok = True)\n",
    "os.makedirs(SPLIT_TRAIN_PATH,exist_ok = True)\n",
    "os.makedirs(SPLIT_TEST_PATH,exist_ok = True)\n",
    "\n",
    "#Let's also include all the subfolders for train and test\n",
    "for label in os.listdir(IMAGES_PATH):\n",
    "\n",
    "    train_path = os.path.join(SPLIT_TRAIN_PATH,label)\n",
    "    test_path = os.path.join(SPLIT_TEST_PATH,label)\n",
    "\n",
    "    os.makedirs(train_path,exist_ok = True)\n",
    "    os.makedirs(test_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d7a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for root, dirs, files in os.walk(IMAGES_PATH):\n",
    "\n",
    "    image_paths = []    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root,file)\n",
    "        image_paths.append(file_path)\n",
    "\n",
    "        key = file.split('0')[0]\n",
    "    images[key] = image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0db63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in images.keys():\n",
    "    np.random.shuffle(images[key]) \n",
    "\n",
    "    for i,image in enumerate(images[key]):\n",
    "\n",
    "        if i < int(0.8*len(images[key])):\n",
    "            genre = key\n",
    "            image_name = os.path.basename(image)\n",
    "            destination_path = os.path.join(SPLIT_TRAIN_PATH,genre,image_name)\n",
    "            shutil.copyfile(image,destination_path)\n",
    "\n",
    "        else:\n",
    "            image_name = os.path.basename(image)\n",
    "            genre = key\n",
    "            destination_path = os.path.join(SPLIT_TEST_PATH,genre,image_name)\n",
    "            shutil.copyfile(image,destination_path)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE579",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
