{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c719b0",
   "metadata": {},
   "source": [
    "# Transfer Learning with Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7eec9",
   "metadata": {},
   "source": [
    "Transfer learning is a powerful technique in machine learning where a model developed for a particular task is reused as the starting point for a model on a second task. This is especially useful when the second task has limited data. Pretrained models, which have been trained on large datasets, can be fine-tuned for specific applications, leading to improved performance and reduced training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52509fc",
   "metadata": {},
   "source": [
    "## Pretraining Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7412af9",
   "metadata": {},
   "source": [
    "Let's start by importing the nessary libraries and specifying some default paths for our training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c04e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3306ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the paths to the data we want to use and where we want to save our models\n",
    "BASE_PATH = r\"C:\\Users\\JTWit\\Documents\\ECE 579\\Datasets\\Split GTZAN Dataset\"\n",
    "\n",
    "TEST_PATH = os.path.join(BASE_PATH,'test')\n",
    "TRAIN_PATH = os.path.join(BASE_PATH,'train')\n",
    "\n",
    "SAVE_PATH = os.path.join(r\"C:\\Users\\JTWit\\Documents\\ECE 579\",\"Transfer Learning Models\")\n",
    "\n",
    "#Make the save path for the neural network just in case it does not yet exist\n",
    "os.makedirs(SAVE_PATH,exist_ok = True)\n",
    "\n",
    "checkpoint_dir = os.path.join(r\"C:\\Users\\JTWit\\Documents\\ECE 579\",'Training Checkpoints')\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962766d",
   "metadata": {},
   "source": [
    "### Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246c002",
   "metadata": {},
   "source": [
    "Next we will specify the required imports for transfer learning for a few select models. The models we will be using for this task are:\n",
    "\n",
    "- VGG16\n",
    "- ResNet50\n",
    "- InceptionV3\n",
    "- MobileNetV2\n",
    "- DenseNet121\n",
    "- EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b68583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import VGG16,ResNet50,InceptionV3,MobileNetV2,DenseNet121,EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13a80f",
   "metadata": {},
   "source": [
    "We can walk through the process of loading these models with pretrained weights and printing their summaries to understand their architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b68c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE =  (432,288,3)\n",
    "CLASSES_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JTWit\\AppData\\Local\\Temp\\ipykernel_20132\\2505797604.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "inceptionv3 = InceptionV3(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "densenet121 = DenseNet121(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "effnetb0 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8213e92",
   "metadata": {},
   "source": [
    "We can print the summaries of each model to understand their architectures. Although, I would not reccomend running this cell as it will produce a lot of output due to the scale of the models we are loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.summary()\n",
    "\n",
    "resnet50.summary()\n",
    "\n",
    "inceptionv3.summary()\n",
    "\n",
    "mobilenetv2.summary()\n",
    "\n",
    "densenet121.summary()\n",
    "\n",
    "effnetb0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99c716",
   "metadata": {},
   "source": [
    "Let's add all of these models to a dictionary for easy access later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debd11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\"vgg16\":vgg16,\n",
    "\"resnet50\":resnet50,\n",
    "\"inceptionv3\":inceptionv3,\n",
    "\"mobilenetv2\":mobilenetv2,\n",
    "\"densenet121\":densenet121,\n",
    "\"effnetb0\":effnetb0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b1883",
   "metadata": {},
   "source": [
    "We can modify the final layers of each model to adapt them to our specific classification task. This typically involves removing the top layer and adding new layers that match the number of classes in our dataset. Let's accomplish this for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40bbd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNFROZEN_LAYERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d714200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, base_model in models.items():\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    prediction_layer = Dense(CLASSES_COUNT, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=prediction_layer)\n",
    "    \n",
    "    # Freeze all layers except last UNFROZEN_LAYERS layers\n",
    "    for layer in model.layers[:-UNFROZEN_LAYERS]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    models[key] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74276f",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630e802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff2f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data(training_path, training_options, validation_split=0.2):\n",
    "    # Create an ImageDataGenerator with validation_split\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=training_options[\"rotation_range\"],\n",
    "        width_shift_range=training_options[\"width_shift_range\"],\n",
    "        height_shift_range=training_options[\"height_shift_range\"],\n",
    "        brightness_range=training_options[\"brightness_range\"],\n",
    "        rescale=1./255,  # Important for scaling pixel values\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "\n",
    "    # Training generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        training_path,\n",
    "        target_size=training_options[\"target_size\"],\n",
    "        batch_size=training_options[\"batch_size\"],\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    # Validation generator\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        training_path,\n",
    "        target_size=training_options[\"target_size\"],\n",
    "        batch_size=training_options[\"batch_size\"],\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38141f5",
   "metadata": {},
   "source": [
    "Now that we have the train and validation generators set up we can configure them for our transfer learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0238cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (432,288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d01890a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 10 classes.\n",
      "Found 159 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data generators\n",
    "train_options = {\n",
    "    \"rotation_range\": 0,           # Slightly reduced\n",
    "    \"width_shift_range\": 0.0,      # Up to 5% shift (1.5 pixels for 30x30)\n",
    "    \"height_shift_range\": 0.,     # Up to 5% shift\n",
    "    \"brightness_range\": (1, 1), # Gentle brightness adjustment\n",
    "    \"target_size\": TARGET_SIZE,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "train_gen,valid_gen = get_train_and_validation_data(TRAIN_PATH,train_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04916ec",
   "metadata": {},
   "source": [
    "## Performing Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6534a86",
   "metadata": {},
   "source": [
    "Let's start by importing the nessicary libraries to perform the transfer learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f47b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime as datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe6d60",
   "metadata": {},
   "source": [
    "Next,we will specify some of the hyperparameters for our training process, such as the number of epochs, batch size, and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19114534",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 30\n",
    "\n",
    "TARGET_SIZE = (432,288)\n",
    "\n",
    "NETWORK_NAME = \"GTZAN Custom DNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b809d",
   "metadata": {},
   "source": [
    "Now that the hyperparameters are set, we can define the loss function, optimizer, and evaluation metrics for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "155f2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models.keys():\n",
    "    models[key].compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8db87",
   "metadata": {},
   "source": [
    "The final step before we can peform our transfer learning is to specify some callbacks to help with the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44f3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2, \n",
    "    patience=2)\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    mode=\"max\", \n",
    "    patience=3)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,  \n",
    "    monitor='val_loss',      \n",
    "    save_best_only=False,    \n",
    "    verbose=1                \n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [reduce_lr,earlystop] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d822e",
   "metadata": {},
   "source": [
    "Finally we are in a place where we can peform transfer learning on our selected models. We will loop through each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models.keys():\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Now training: {key}\")\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    history = models[key].fit(train_gen, validation_data=valid_gen, epochs=EPOCHS, callbacks = callbacks)\n",
    "        \n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "    name_string = f\"{key} (accuracy = {accuracy:.4f})(date = {date_str}).keras\"\n",
    "\n",
    "    save_file = os.path.join(SAVE_PATH,name_string)\n",
    "\n",
    "    models[key].save(save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f66368",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e570b",
   "metadata": {},
   "source": [
    "Similar to the DNN / CNN based models, we can evaluate the performance of our transfer learned models using various metrics and visualizations. \n",
    "\n",
    "We will start by defining a function to get a test data generator similar to our training and validation generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(test_path, testing_options):\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rotation_range=testing_options[\"rotation_range\"],\n",
    "        width_shift_range=testing_options[\"width_shift_range\"],\n",
    "        height_shift_range=testing_options[\"height_shift_range\"],\n",
    "        brightness_range=testing_options[\"brightness_range\"],\n",
    "        rescale=1./255\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=testing_options[\"target_size\"],\n",
    "        batch_size=testing_options[\"batch_size\"],\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17896e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_options = {\n",
    "    \"rotation_range\": 0,              \n",
    "    \"width_shift_range\": 0,\n",
    "    \"height_shift_range\": 0,\n",
    "    \"brightness_range\": (1, 1),       \n",
    "    \"target_size\": TARGET_SIZE,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "test_gen = get_test_data(TEST_PATH,test_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba1823",
   "metadata": {},
   "source": [
    "Now that we have a test generator, we can evaluate each of our transfer learned models on the test dataset. This will give us an unbiased estimate of how well our models perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: vgg16\n",
      "Model: resnet50\n",
      "Model: inceptionv3\n",
      "Model: mobilenetv2\n",
      "Model: densenet121\n",
      "Model: effnetb0\n"
     ]
    }
   ],
   "source": [
    "for key,model in models.items():\n",
    "    print('-'*100)\n",
    "    print(f\"Model: {key}\")\n",
    "    print('-'*100)\n",
    "\n",
    "    results = model.evaluate(test_gen)\n",
    "    print('Test loss:', results[0])\n",
    "    print('Test accuracy:', results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE579",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
